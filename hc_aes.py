# -*- coding: utf-8 -*-
"""HC-AES.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18NxM5kCjnAZM9CnBdiA_eBhza7xBdLka

#**Hotel-Cancellation-Prediction-using-Auto-Encoders-and-KNN**
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import zipfile

zip=zipfile.ZipFile('1-s2.0-S2352340918315191-mmc2 (1).zip')
zip.extractall()

"""**Combining two dataframes into a single dataframe**"""

df1=pd.read_csv('H1.csv')
df2=pd.read_csv('H2.csv')
frames=[df1,df2]
df = pd.concat(frames)

df=df.dropna(how='any')
df['Cancelled']=df['IsCanceled']
df['Children']=df['Children'].astype(int)
df['ADR']=df['ADR'].astype(int)
df['ArrivalDateYear']=df['ArrivalDateYear'].astype(int)
df=df.drop(columns=['ReservationStatusDate','IsCanceled','MarketSegment','DistributionChannel','ArrivalDateYear','LeadTime','Company','ADR','Agent'])
df

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
le1=LabelEncoder()
le2=LabelEncoder()
le3=LabelEncoder()
le4=LabelEncoder()
le5=LabelEncoder()
le6=LabelEncoder()
le7=LabelEncoder()
le8=LabelEncoder()
le9=LabelEncoder()
le10=LabelEncoder()
df['ArrivalDateMonth']=le.fit_transform(df['ArrivalDateMonth'])
df['Meal']=le1.fit_transform(df['Meal'])
#df['MarketSegment']=le4.fit_transform(df['MarketSegment'])
#df['DistributionChannel']=le5.fit_transform(df['DistributionChannel'])
df['ReservedRoomType']=le6.fit_transform(df['ReservedRoomType'])
df['AssignedRoomType']=le6.fit_transform(df['AssignedRoomType'])
df['DepositType']=le7.fit_transform(df['DepositType'])
df['Country']=le8.fit_transform(df['Country'])
df['CustomerType']=le9.fit_transform(df['CustomerType'])
df['ReservationStatus']=le10.fit_transform(df['ReservationStatus'])

df

X=df.iloc[:,:-1].values
y=df.iloc[:,-1].values

print(X.shape, y.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)

"""**Structuring Multilayer Perceptron (MLP)  Auto Encoder model**"""

from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.models import Model
from tensorflow.keras.utils import plot_model
n_inputs=22

"""**Encoder Layout**"""

# define encoder
visible = Input(shape=(n_inputs,))
# encoder level 1
e = Dense(n_inputs*2)(visible)
e = BatchNormalization()(e)
e = LeakyReLU()(e)
# encoder level 2
e = Dense(n_inputs)(e)
e = BatchNormalization()(e)
e = LeakyReLU()(e)
# bottleneck
n_bottleneck = n_inputs
bottleneck = Dense(n_bottleneck)(e)

"""**Decoder Layout**"""

# define decoder, level 1
d = Dense(n_inputs)(bottleneck)
d = BatchNormalization()(d)
d = LeakyReLU()(d)
# decoder level 2
d = Dense(n_inputs*2)(d)
d = BatchNormalization()(d)
d = LeakyReLU()(d)
# output layer
output = Dense(n_inputs, activation='linear')(d)
# define autoencoder model
model = Model(inputs=visible, outputs=output)

model.compile(optimizer='adam', loss='mse')

"""**Strucuture of Autoencoder**"""

plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)

history = model.fit(X_train, y_train, epochs=200, batch_size=1600, verbose=2, validation_data=(X_test,y_test))

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show()

encoder = Model(inputs=visible, outputs=bottleneck)
plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)
# save the encoder to file
encoder.save('HC-encoder.h5')

"""**Testing K- Nearest Neighbours  alone for the inputs**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

mod = KNeighborsClassifier()
mod.fit(X_train, y_train)

y_pred = mod.predict(X_test)
predictions = np.round(y_pred,1)

predictions

accuracy = accuracy_score(y_test, predictions)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

"""**Applying K-Nearest Neighbours learning in conjunction with the model**"""

from tensorflow.keras.models import load_model

encoder = load_model('HC-encoder.h5')

# encode the train data
X_train_encode = encoder.predict(X_train)
# encode the test data
X_test_encode = encoder.predict(X_test)
# define the model
model = KNeighborsClassifier()
# fit the model on the training set
model.fit(X_train_encode, y_train)
# make predictions on the test set
yhat = model.predict(X_test_encode)
# calculate classification accuracy
acc = accuracy_score(y_test, yhat)
print("Accuracy: %.2f%%" % (acc * 100.0))